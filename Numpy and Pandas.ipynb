{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "881440a7",
   "metadata": {},
   "source": [
    "## Importing numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b3bf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a9767c",
   "metadata": {},
   "source": [
    "## Array: The Fundamental Data Structure in Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c837bd7",
   "metadata": {},
   "source": [
    "Numpy is fundamentally based on arrays, N-dimensional data structures. Here we mainly stay with one- and two-dimensional structures (vectors and matrices) but the arrays can also have higher dimension (called tensors). Besides arrays, numpy also provides a plethora of functions that operate on the arrays, including vectorized mathematics and logical operations.\n",
    "\n",
    "Arrays can be created with np.array. For instance, we can create a 1-D vector of numbers from 1 to 4 by feeding a list of desired numbers to the np.array\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccab4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,4])\n",
    "print(\"a:\\n\", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b71558",
   "metadata": {},
   "source": [
    "Note that it is printed in brackets as list, but unlike a list, it does not have commas separating the components."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acde280e",
   "metadata": {},
   "source": [
    "If we want to create a matrix (two-dimensional array), we can feed np.array with a list of lists, one sublist for each row of the matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee6d151",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([[1,2], [3,4]])\n",
    "print(\"b:\\n\", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92d3064",
   "metadata": {},
   "source": [
    "The output does not have the best formatting but it is clear enough."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b829c4",
   "metadata": {},
   "source": [
    "One of the fundamental property of arrays is its dimension, called shape in numpy. Shape is array’s size along all of its dimensions. This can be queried by attribute .shape which returns the sizes in a form of a tuple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c40730",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa57224",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9247377b",
   "metadata": {},
   "source": [
    "One can see that vector a has a single dimension of size 4, and matrix b has two dimensions, both of size 2 (remember: (4,) is a tuple of length 1!)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbfeece",
   "metadata": {},
   "source": [
    "One can also reshape arrays, i.e. change their shape into another compatible shape. This can be achieved with .reshape() method. .reshape takes one argument, the new shape (as a tuple) of the array. For instance, we can reshape the length-4 vector into a 2x2 matrix as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0c8c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.reshape((2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9028996a",
   "metadata": {},
   "source": [
    "and we can “straighten” matrix b into a vector with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf355087",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.reshape((4,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea886cc",
   "metadata": {},
   "source": [
    "## Creating Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8a0ac2",
   "metadata": {},
   "source": [
    "Sometimes it is practical to create arrays manually as we did above, but usually it is much more important to make those by computation. Below we list a few options.\n",
    "\n",
    "np.arange creates sequences, quite a bit like range, but the result will be a numpy vector. If needed, we can reshape the vector into a desired format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3680eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(10)  # vector of length 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f113cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(10).reshape((2,5))  # 2x5 matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ce6ced",
   "metadata": {},
   "source": [
    "np.zeros and np.ones create arrays filled with zeros and ones respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e91c532",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros((5,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e83696",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ones((2,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d95f840",
   "metadata": {},
   "source": [
    "Arrays can be combined in different ways, e.g. np.column_stack combines them as columns (next to each other), and np.row_stack combines these as rows (underneath each other). For instance, we can combine a column of ones and two columns of zeros as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa39d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "oneCol = np.ones((5,))  # a single vector of ones\n",
    "zeroCols = np.zeros((5,2))  # two columns of zeros\n",
    "np.column_stack((oneCol, zeroCols))  # 5x3 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b011df18",
   "metadata": {},
   "source": [
    "Note that column_stack expects all arrays to be passed as a single tuple (or list)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89afe2e",
   "metadata": {},
   "source": [
    "## Vectorized Functions (Universal Functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d604f148",
   "metadata": {},
   "source": [
    "It is possible to use loops to do computation with numpy objects exactly in the same way when working with lists. However, one should use vectorized operations instead whenever possible. Vectorized operations are easier to code, easier to read, and result in faster code.\n",
    "\n",
    "Numpy offers a plethora of vectorized functions and operators, called universal functions. Many of these work as expected. For instance, mathematical operations. We create a matrix, and then add “100” to it, and then rise “2” to the power of the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58368f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(12).reshape((3,4))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272a64a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(100 + a, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ba5458",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(2**a, \"\\n\")  # remember: exponent with **, not with ^"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4680ac4",
   "metadata": {},
   "source": [
    "Both of these mathematical operations, + and ** are performed elementwise for every single element of the matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a6f1d0",
   "metadata": {},
   "source": [
    "create matrix of even numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac60447",
   "metadata": {},
   "outputs": [],
   "source": [
    "2 + 2*np.arange(20).reshape(4,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a10098f",
   "metadata": {},
   "source": [
    "Comparison operators are vectorized too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55dd9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a > 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57526c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a == 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de8533b",
   "metadata": {},
   "source": [
    "As comparison operators are vectorized, one might expect that the other logical operators, and, or and not, are also vectorized. But this is not the case. There are vectorized logical operators, but they differ from the base python version. These are more similar to corresponding operators in R or C, namely & for logical and, | for logical or, and ~ for logical not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49411b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "(a < 3) | (a > 8)  # logical or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b108126",
   "metadata": {},
   "outputs": [],
   "source": [
    "(a > 4) & (a < 7)  # logical and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87194a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "~(a > 6)  # logical not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a3da87",
   "metadata": {},
   "source": [
    "There is no vectorized multi-way comparison like 1 < x < 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c70b50f",
   "metadata": {},
   "source": [
    "## Array Indexing and Slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba1e1e1",
   "metadata": {},
   "source": [
    "Indexing refer to extracting elements based on their position or certain criteria. This is one of the fundamental operations with arrays. There are two ways to extract elements: based on position, and based on logical criteria. Unfortunately, this also makes indexing somewhat confusing, and it needs some time to become familiar with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5dca96",
   "metadata": {},
   "source": [
    "### Extracting elements based on position"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284ecc53",
   "metadata": {},
   "source": [
    "Array indexing is very similar to list indexing. As matrices have two dimensions, we need two indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc6724a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(12)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1f02f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a[::2])  # every second element"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107dc774",
   "metadata": {},
   "source": [
    "However, unlike lists, one can do vectorized assignments in numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f105f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[5:11] = -1  # assign multiple elements\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee80b78",
   "metadata": {},
   "source": [
    "One can also extract multiple elements from a vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d6d0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[[4,5,7]]  # extract 3 elements in one go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c263ed",
   "metadata": {},
   "source": [
    "When working with matrices (2-D arrays), we need two indices, separated by comma. Comma separates two slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cbe812",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.arange(12).reshape((3,4))\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c9f31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "c[1,2]  # 2nd row, 3rd column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63969067",
   "metadata": {},
   "outputs": [],
   "source": [
    "c[1] # 2nd row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886495a3",
   "metadata": {},
   "source": [
    "Comma can separate not just two indices but two slices, so we can write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cf2deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "c[:,2]  # all rows, 3rd column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfc22b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "c[:2]  # 1st, 2nd row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c5c0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "c[:2, :3]  # 1s, 2nd row, first three columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67def11e",
   "metadata": {},
   "source": [
    "Create matrix and access rows and columns\n",
    "\n",
    "create a 4x5 array of even numbers: 10, 12, 14, …\n",
    "extract third column\n",
    "set the fourth row to 1,2,3,4,5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d49d9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=10+(2*np.arange(20).reshape((4,5)))  #create a 4x5 array of even numbers: 10, 12, 14\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49af00a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[:,2]    #extract third column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ce1c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[3]=[1,2,3,4,5]  #set the fourth row to 1,2,3,4,5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efff15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2386389",
   "metadata": {},
   "source": [
    "### Boolean indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655c5263",
   "metadata": {},
   "source": [
    "An extremely widely used approach is to extract elements of an array based on a logical criteria. Fundamentally, it is just using a logical vector for indexing. The vector must be of the same lengts as the array in question, and the results contains only those elements the correspond to True in the indexing vector. Here is an example how we can do this manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8945bfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,7,8])\n",
    "i = np.array([True, False, True, False])\n",
    "a[i]  # 1, 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edeaccf",
   "metadata": {},
   "source": [
    "The previous example–manually creating a logical index vectors of trues and falses is hardly ever useful. Almost always we use logical operations instead. For instance, we can extract all elements of a that are greater than 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725639a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = a > 5\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d51301",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae8d025",
   "metadata": {},
   "source": [
    "This is often written in a more compact manner by skipping explicit logical vector i:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bb349d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[a > 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673da8c0",
   "metadata": {},
   "source": [
    "New users of numpy (and other languages that support logical indexing) sometimes forget that the logical condition does not have to be related to the same array that we are attempting to extract. For instance, we can extract all results for a certain person:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170b9df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = np.array([\"Cyrus\", \"Darius\", \"Xerxes\", \"Artaxerxes\", \"Cyrus\", \"Darius\"])\n",
    "results = np.array([17, 14, 20, 18, 13, 15])\n",
    "results[names == \"Darius\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b55e69",
   "metadata": {},
   "source": [
    "Here index vector is based on the variable name only and is not directly related to results. However, we use it to extract values from the latter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abdb834",
   "metadata": {},
   "source": [
    "Finally, we also can extract rows (or columns) from a 2-D array in a fairly similar fashion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3204ea31",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = np.array([\"Cyrus\", \"Darius\", \"Xerxes\"])\n",
    "results = np.array([[17, 14], [20, 18], [13, 15]])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253a9c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[names == \"Darius\",:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477c6e63",
   "metadata": {},
   "source": [
    "Logical indexing can also be used on the left-hand-side of the expression, in order to replace elements. Below is an example where we replace all the negative elements of a with zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5577528",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randn(2,3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b1c944",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[a < 0] = 0\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68194df4",
   "metadata": {},
   "source": [
    "When replacing elements in such fashion then we need to supply the replacement vector that is either length 1 (all elements are replaced by “0” in the example above), or alternatively we should supply a replacement vector of correct length. For instance, we can replace the positive numbers left in a with 1, 2, 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334bb732",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[a > 0] = np.array([1, 2, 3])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eac6dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = np.array([\"Roxana\", \"Statira\", \"Roxana\", \"Statira\", \"Roxana\"])\n",
    "score = np.array([126, 115, 130, 141, 132])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983e1f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    " score[score<130] #Extract all test scores that are smaller than 130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401ae8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "score[names==\"Statira\"]          #Extract all test scores by Statira#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d31f9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "score[names==\"Roxana\"] + 10            #Add 10 points to Roxana’s scores. (You need to extract it first.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3ae0ec",
   "metadata": {},
   "source": [
    "## Random numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a449487c",
   "metadata": {},
   "source": [
    "Numpy offer a large set of random number generators. These can be invoked as np.random.generator(params, size). For instance, np.random.choice(N) can be used to create random numbers from 0 to  \n",
    "N−1. size determines the shape of the resulting object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305b23f4",
   "metadata": {},
   "source": [
    " The argument is size, not shape, although it determines the output shape!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1af76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.choice(6, size=5)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba754bb",
   "metadata": {},
   "source": [
    "But maybe we prefer not to label the results as 0..5 but 1..6. So we can just add one to the result. Here is an example that creates 2-D array of die rolls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b193c88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 + np.random.choice(6, size=(2,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec2d30d",
   "metadata": {},
   "source": [
    "Numpy offers a large set of various random values. Here we list a few more:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d064b2",
   "metadata": {},
   "source": [
    "#### Random elements from list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed3787a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nucleotides = [\"A\", \"G\", \"C\", \"T\"]\n",
    "dna = np.random.choice(nucleotides, 20)\n",
    "\"\".join(dna)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb20f7dc",
   "metadata": {},
   "source": [
    "As the example demonstrates, random.choice picks random elements with replacement (use replace option to change this behavior)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da551bc",
   "metadata": {},
   "source": [
    "#### Random normals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266573e0",
   "metadata": {},
   "source": [
    "random.normal(loc, scale, size) generates normally distributed random numbers. The distribution is centered at loc and its variance is scale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f478c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.normal(1000, 100, size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aba721c",
   "metadata": {},
   "source": [
    "#### Binomial random numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb894ca",
   "metadata": {},
   "source": [
    "random.binomial(n, p, size) creates random binomials where probability of success is p and sample size is n:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ca2e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.binomial(2, 0.5, size=(2,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81400d23",
   "metadata": {},
   "source": [
    "We can describe a coin toss as Binomial(1, 0.5) where 1 refers to the fact that we toss a single coin, and 0.5 means it has probability 0.5 to come heads up. So such random variables are sequences of zeros and ones. But how can we get a sequence of -1 and 1 instead? Demonstrate it on computer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bb4a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "2*np.random.binomial(1, 0.5, size=10) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf4f68d",
   "metadata": {},
   "source": [
    "#### Uniform random numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f599733a",
   "metadata": {},
   "source": [
    "random.uniform(low, high, size) creates uniformly distributed random numbers in the interval [low, high]:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58362ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.uniform(-1, 1, size=(3,4))  # random numbers in [-1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dd592c",
   "metadata": {},
   "source": [
    "#### Repeating the exact same random sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9124e3c",
   "metadata": {},
   "source": [
    "The random numbers are often called pseudorandom as they are not truly random–they are computed based on a well-defined algorithm, so when feeding the same initial values to the algorithm, one always gets the same random numbers. However, normally the initial values are taken from certain hart-to-control parameters outside of the program control, such as time in microseconds and hard disk serial number, so in practice it is impossible to replicate the same sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f9999c",
   "metadata": {},
   "source": [
    "However, if you need to replicate your results exactly, you have to set the initial values explicitly using random.seed(value). This re-initializes RNG-s to the given initial state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415f099e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "np.random.uniform(size=5)  # 1st batch of numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae8cbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.uniform(size=5)  # 2nd batch is different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf0cd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "np.random.uniform(size=5)  # repeat the 1st batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aa1320",
   "metadata": {},
   "source": [
    "#### Statistical functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49533570",
   "metadata": {},
   "source": [
    "Numpy offers a set of basic statistical functions, including sum, mean, and standard deviations std. These can be applied to the array as a whole, or separately to rows or columns. In the latter case one has to specify the argument axis, where the value 0 means to apply the operation row-wise (and preserve columns) and axis=1 means to apply the operation column-wise (and preserve rows). Here is an example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec72e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(12).reshape((3,4))\n",
    "a  # 3 rows, 4 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ba6129",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.sum()  # total sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ebc593",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.sum(axis=0)  # add rows, preserve columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69029289",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.sum(axis=1)  # add columns, preserve rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2380d9e9",
   "metadata": {},
   "source": [
    "The functions come in two forms: as a method x.sum(), and as a separate function np.sum(x). These two ways are pretty much equivalent.\n",
    "\n",
    "By default, a missing value of an array causes the function to return missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631ed12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.astype(float)  # as np.nan is float, need a float array\n",
    "a[1,2] = np.nan\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c37f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b631315",
   "metadata": {},
   "source": [
    " This differs from the corresponding functionality in pandas where missings are ignored by default!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857b1fc5",
   "metadata": {},
   "source": [
    "The other statistical functions include\n",
    "\n",
    "mean for average\n",
    "median for median\n",
    "var for variance\n",
    "std for standard deviation\n",
    "np.percentile and np.quantile for quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b711fff",
   "metadata": {},
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55cea71",
   "metadata": {},
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cb7270",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pandas is the standard python library to work with dataframes.  It is typically imported as pd:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b670ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57736572",
   "metadata": {},
   "source": [
    "Pandas contains two central data types: Series and DataFrame. Series is often used as a second-class citizen, just as a single variable (column) in data frame. But it can also be used as a vectorized dict that links keys (indices) to values. DataFrame is broadly similar to other dataframes as implemented in R or spark. When you extract its individual columns and rows you normally get those in the form of Series. So it is extremely useful to know the basics of Series when working with data frames. Both DataFrame and Series include index, a glorified row name, which is very useful for extracting information based on names, or for merging different variables into a data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bcfb7c",
   "metadata": {},
   "source": [
    "### Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb3c99b",
   "metadata": {},
   "source": [
    "Series is a one-dimensional positional column (or row) of values. It is in some sense similar to list, but from another point of view it is more like a dict, as it contains index, and you can look up values based on index as a key. So it allows not only positional access but also index-based (key-based) access. In terms of internal structure, it is implemented with vectorized operations in mind, so it supports vectorized arithmetic, and vectorized logical, string, and other operations. Unlike dicts, it also supports multi-element extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58478a9",
   "metadata": {},
   "source": [
    "Let’s create a simple series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28931b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1,2,5,6])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e23fbf",
   "metadata": {},
   "source": [
    "Series is printed in two columns. The first one is the index, the second one is the value. In this example, index is essentially just the row number and it is not very useful. This is because we did not provide any specific index and hence pandas picked just the row number. Underneath the two columns, you can also see the data type, in this case it is 64-bit integer, the default data type for integers in python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648892a4",
   "metadata": {},
   "source": [
    "Now let’s make another example with a more informative index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647f1f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = pd.Series( [ 38, 26, 19, 19],\n",
    "                 index = ['ca', 'tx', 'ny', 'fl'])\n",
    "# population, in millions\n",
    "pop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa17b87",
   "metadata": {},
   "source": [
    "Now the index is helpful: we are looking at state populations, and index tells us which state is in which row. Another advantage of possessing index is that even when we filter and manipulate the series, it’s index will still retain the original row label. So we know that index “fl” will always correspond to Florida. But if we have removed a few cases, or re-ordered the series, then Florida may not be on the fourth position any more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4b4b10",
   "metadata": {},
   "source": [
    "Create a series of 4 capital cities where the index is the name of corresponding country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e3382b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = pd.Series([\"Brazzaville\", \"Libreville\", \"Malabo\", \"Yaoundé\"],\n",
    "                   index=[\"Congo\", \"Gabon\", \"Equatorial Guinea\", \"Cameroon\"])\n",
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270aaa6a",
   "metadata": {},
   "source": [
    "We can extract values and index using the corresponding attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4382925",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf041e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2021502",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8538bcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca01af72",
   "metadata": {},
   "source": [
    "Note that values are returned as np array, and index is a special index object. If desired, this can be converted to a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ce7030",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(pop.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0371d6d",
   "metadata": {},
   "source": [
    "Series also supports ordinary mathematics, e.g. we can do operations like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550a14fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop > 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3ec389",
   "metadata": {},
   "source": [
    "the result will be another series, here of logical values, as indicated by the “bool” data type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af9edfe",
   "metadata": {},
   "source": [
    "### DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a94926",
   "metadata": {},
   "source": [
    "DataFrame is the central data structure for holding 2-dimensional rectangular data. It is in many ways similar to R dataframes. However, it also shares a number of features with Series, in particular the index, so you can imagine a data frame is just a number of series stacked next to each other. Also, extracting single rows or columns from DataFrames typically results in a series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6cfbd6",
   "metadata": {},
   "source": [
    "#### Creating data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1f01e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {'ca': [35, 37, 38], 'tx': [23, 24, 26], 'md': [5,5,6]}\n",
    "pop = pd.DataFrame(df)\n",
    "print('population:\\n', pop, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00caebf2",
   "metadata": {},
   "source": [
    "The data frame is printed as four columns. Exactly as in case of series, the first column is index. In the example above we did not specify the index and hence pandas picked just row numbers. But we can provide an explicit index, for instance the year of observation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d0e202",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = pd.DataFrame(df, index = [2010,2012,2014])\n",
    "print('population:\\n', pop, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bce692",
   "metadata": {},
   "source": [
    "In this case the index is rather useful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a023ef",
   "metadata": {},
   "source": [
    "Create a dataframe of (at least 4) countries, with 2 variables: population and capital. Country name should be the index.\n",
    "\n",
    "Hint: feel free to invent populations!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e9e665",
   "metadata": {},
   "source": [
    "#### Read data from file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b20444b",
   "metadata": {},
   "source": [
    "To create data frames manually is useful for testing and debugging, in real applications we typically read data from disk. This can be done with pd.read_csv that takes the file name as the first argument, and also supports many other options. In the example below, we read data about G.W.Bush approval rate in fall 2001. pd.read_csv assumes files are comma-separated by default, but as this example file is tab-separated we have to declare it using sep=\"\\t\" as an extra argument. We also read the first 10 rows only for demonstration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46329229",
   "metadata": {},
   "outputs": [],
   "source": [
    "approval = pd.read_csv('https://bitbucket.org/otoomet/lecturenotes/raw/master/data/gwbush-approval.csv', \\\n",
    " sep='\\t', nrows=10) \n",
    "approval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09a4e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv('https://bitbucket.org/otoomet/lecturenotes/raw/master/data/gwbush-approval.csv')  # wrong separator\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d98b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c90487",
   "metadata": {},
   "source": [
    "Two problems are immediately visible: first, the file contains a single column only (because it does not consider tab symbols as separators), and the two lines we printed look weird. If you ask for variable names, you can also see that all variable names are combined together into a single weird name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e17816e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef814b0",
   "metadata": {},
   "source": [
    "The tab markers \\t in printout give strong hints that the correct separator is tab.\n",
    "\n",
    "It may initially be quite confusing to understand how to specify the file name. If you load data in a jupyter notebook, then the working directory is normally the same directory where the notebook is located3. Notebook also let’s you to complete file names with TAB key. But in any case, the working directory can be found with os.getcwd (get current working directory):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4147b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137dede0",
   "metadata": {},
   "source": [
    "This helps to specify the relative path if your data file is not located in the same place as your code. You can also find which files does python find in a given folder, e.g. in ../data/:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a20c51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(\"../'1.7 Introduction to NumPy'/\")\n",
    "files[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369f48b4",
   "metadata": {},
   "source": [
    "As another complication, notebooks are often run on a separate server or in a docker container. These may have no access to files in your computer (as the server), or only have a limited access (like docker container). In such a case, you should upload the file to notebook, even if it is running on your computer!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40727e62",
   "metadata": {},
   "source": [
    "# Indexing data frames and series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428f55ac",
   "metadata": {},
   "source": [
    "Indexing refers to selecting data from data frames and series based on variable names, logical conditions, and position. It is a complex task with many different methods, and unfortunately also with many caveats. Below, the topic is split into several subsections:\n",
    "\n",
    "Select variables explains how to select desired variables from a data frame\n",
    "Filter observations with logical operations describes how to filter rows\n",
    "Positional indexing of Series introduces positional indexing, indexing based on row number, and how to do it with series\n",
    "Positional indexing of data frames explains positional indexing, indexing based on both row and column numbers, for data frames\n",
    "Modifying data frames: there are slight differences when modifying data instead of extracting, these are discussed here.\n",
    "Indexing: summary and comparison provides a summary of all methods.\n",
    "Fortunately, Series and data frames behave in a broadly similar way, e.g. selecting cases by logical conditions, based on index, and location are rather similar. As series do not have columns, we cannot access elements by column name or by column position though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72e0d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download CSV with read_csv\n",
    "df = pd.read_csv('https://bitbucket.org/otoomet/lecturenotes/raw/master/data/gwbush-approval.csv', \\\n",
    " sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2548b441",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b633f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "approval.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c17dab",
   "metadata": {},
   "source": [
    "To begin with, data frames have variable names. We can extract a single variable either with [\"varname\"] or a shorthand as attribute .varname (note: replace varname with the name of the relevant variable):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fd9ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "approval[\"approve\"]  # approval, as series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f091ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "approval.approve  # the same, as series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd80ba32",
   "metadata": {},
   "source": [
    "These constructs return the column as a series. If we prefer to get a single-column data frame, we can wrap the variable name into a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63634b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "approval[[\"approve\"]]  # approval, as data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4590dc",
   "metadata": {},
   "source": [
    "The attribute shorthand is usually the easier way, but it does not work if you need to use indirect variable name (variable name that is stored in another variable) or if the variable name contains spaces or other special characters. It also does not work for creating new variables in the data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac66e42c",
   "metadata": {},
   "source": [
    "The previous example where we extracted a single column as a data frame instead of Series also hints how to extract more than one variable: just wrap all the required variable names into a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f887c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = [\"date\", \"approve\"]\n",
    "approval[vars]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3163836d",
   "metadata": {},
   "source": [
    "There are no attribute shortcuts to extract multiple columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c933b7e5",
   "metadata": {},
   "source": [
    "### Filter observations with logical operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c458ef1",
   "metadata": {},
   "source": [
    "Filtering refers to extracting only a subset of rows from the dataframe based on certain conditions. The conditions are logical operations that can be either true or false, depending on the values in each row. Filtering produces a sub-dataframe where only those observations that meet the selection criteria are present: Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29694c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "approval[approval.approve > 88]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86995f67",
   "metadata": {},
   "source": [
    "Note that we have to refer to data variables as approval.approve, not just approve, unlike in R dplyr where one can just write approve. This is somewhat harder to write but it is less ambiguous and produces fewer hard-to-find bugs.\n",
    "\n",
    "Obviously we can use more complex selection conditions, for instance we can look for very low or very high approval rates as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38819967",
   "metadata": {},
   "outputs": [],
   "source": [
    "approval[(approval.approve < 86) | (approval.approve > 89)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4561c6c",
   "metadata": {},
   "source": [
    "Note that we are using the vectorized “or” operator |, not the base python or. We also need to wrap both the “less than” and “greater than” parts in parenthesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100086e2",
   "metadata": {},
   "source": [
    "How many polls in the data show the president’s approval rate at least 88%? At which dates are those polls conducted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7474fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "approval[approval.approve >= 88][[\"date\", \"approve\"]]  # only print date,\n",
    "    # approval rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e926dc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "approval[approval.approve >= 88].shape[0]  # data for at least 90% approval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2441fca2",
   "metadata": {},
   "source": [
    "The filtered object is not a new data frame but a view of the original data frame. This may give you warnings and errors later when you attempt to modify the filtered data. If you intend to do that, perform a deep copy of data using the .copy method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6220d970",
   "metadata": {},
   "source": [
    "### Positional indexing of Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993d941e",
   "metadata": {},
   "source": [
    "Besides selecting variables and filtering by logical conditions, we occasionally need to access elements by index, or by position (location). Here we demonstrate the positional indexing using a series object, positional indexing of data frames is discussed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f97da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = pd.Series([32.7, 267.7, 15.3],  # in millions\n",
    "                index=[\"MY\", \"ID\", \"KH\"])\n",
    "pop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7d71c7",
   "metadata": {},
   "source": [
    "We can access series’ values in two ways: by position, and by index. In order to access elements by position, we have to use attribute .iloc[] where i loc refers to “integer”. Unlike most other methods, .iloc expects arguments in brackets. A single number in brackets returns the element as an element (e.g. a single number), if brackets contain a list (this looks like double brackets), it returns a series, potentially containing only a single element. So in order to extract 2nd and 3rd element in the population series, we can write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f5b54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop.iloc[1]  # extract 2nd element as a number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bc8aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop.iloc[[1,2]]   # extract 2nd, 3th as a series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f051dea7",
   "metadata": {},
   "source": [
    "Alternatively, we can also extract the elements by index. This works in a similar fashion, except we have to use .loc[] instead of .iloc[]. The rules for single and double brackets apply in the similar fashion as in case of positional access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baad9e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop.loc[\"ID\"]  # extract Indonesian population as a number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220f75b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop.loc[[\"ID\", \"MY\"]]  # extract Indonesian and Malaysian population\n",
    "# as a series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be00ba37",
   "metadata": {},
   "source": [
    "One can also drop the .loc[] syntax and just use square brackets, so instead of writing pop.loc[[\"ID\", \"MY\"]], one can just write pop[[\"ID\", \"MY\"]]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9e9e6d",
   "metadata": {},
   "source": [
    "The fact that there are several ways to extract positional data causes a lot of confusion for beginners. It is not helped by the common habit of not using indices and just relying on the automatic row-numbers. In this case positional access by .iloc[] produces exactly the same results as the index access by .loc[], and one can conveniently forget about the index and use whatever feels easier. But sometimes the index changes as a result of certain operations and that may lead to errors or unexpected results. For instance, we can create an alternative population series without explicit index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f982d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop1 = pd.Series([np.nan, 26, 19, 13])  # index is 0, 1, ...\n",
    "pop1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed8e92f",
   "metadata": {},
   "source": [
    "In this example, position and index are equivalent and hence it is easy to forget that .loc[] is index-based access, not positional access! So one may freely mix both methods (and remember, .loc is not needed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092505f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop1.loc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae16bf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop1.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68db4a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop1[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c77f0f",
   "metadata": {},
   "source": [
    "This becomes a problem if a numeric index is not equivalent to row number any more, for instance after we drop missings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6af108",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop2 = pop1.dropna()  # remove missings\n",
    "pop2  # note: the first row has index 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892d4773",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop2.iloc[2]  # this is by position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f689c1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop2.loc[2]  # this is by index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd977fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop2[2]  # also by index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a4c0bb",
   "metadata": {},
   "source": [
    "Additionally, if pop2 for some reason turns into a numpy array, then pop2[2] is is based on position as arrays do not have index!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcee6913",
   "metadata": {},
   "source": [
    "### Positional indexing of data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa5ab89",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = pd.DataFrame({\"capital\":[\"Kuala Lumpur\", \"Jakarta\", \"Phnom Penh\"],\n",
    "                     \"population\":[32.7, 267.7, 15.3]},  # in millions\n",
    "                    index=[\"MY\", \"ID\", \"KH\"])\n",
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8516a8f7",
   "metadata": {},
   "source": [
    "(MY is Malaysia, ID Indonesia and KH is Cambodia)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075e87d3",
   "metadata": {},
   "source": [
    "Exactly as series, data frames allow positional access by .iloc[]. However, as data frames are two-dimensional objects, .iloc accepts two arguments (in brackets, separated by comma), the first one for rows, the second one for columns. So we can write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f785aab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.iloc[2]  # 3rd row, as series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d83cf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.iloc[[2]]  # 3rd row, as data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da842bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.iloc[2,1]  # 3rd row, 2nd column, as a number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc6725b",
   "metadata": {},
   "source": [
    "There is also an index-based extractor .loc[] that accepts one (for rows) or two (for rows and columns) indices. In case of data frames, the default row index is just the row number; but the column index is the variable names. So we can write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ca7c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.loc[\"MY\",\"capital\"]  # Malaisian capital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4919c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.loc[[\"KH\", \"ID\"], [\"population\", \"capital\"]]\n",
    "                          # Extract a sub-dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5d8513",
   "metadata": {},
   "source": [
    "Unfortunately, data frames add their confusing constructs. When accessing data frames with .loc[] then we have to specify rows first, and possibly columns second. If we drop .loc then we cannot specify rows. That is, unless we extract one variable with brackets, get a series and extract the desired row in the second set of brackets…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9a788f",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries[\"capital\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf39e71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries[\"capital\"][\"MY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a34c1ba",
   "metadata": {},
   "source": [
    "Finally, remember that 2-D numpy arrays will use similar integer-positional syntax as .iloc[], just without .iloc.\n",
    "\n",
    "In conclusion, it is very important to know what is your data type when using numpy and pandas. Indexing is all around us when working with data, there are many somewhat similar ways to extract elements, and which way is correct depends on the exact data type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44660404",
   "metadata": {},
   "source": [
    "### Modifying data frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b6fba5",
   "metadata": {},
   "source": [
    "Modifying data frames can be done in a broadly similar way as extracting elements, you just need to put the expression on the left-hand side.\n",
    "\n",
    "We can create a new column by assigning a list to a new column name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a354563",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries[\"temperature\"] = [27.7, 26.1, 26.6]  # daily mean, January\n",
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdba0ab",
   "metadata": {},
   "source": [
    "One can also overwrite an existing column in a similar fashion.\n",
    "\n",
    "However, there are several exceptions and caveats. Let’s demonstrate this by modifying the data frame of three countries we created above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f1eabc",
   "metadata": {},
   "source": [
    "### One cannot create variables with dot-attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1a402f",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.foo = [1, 2, 3]  # does not work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c28aa48",
   "metadata": {},
   "source": [
    "But after we have created a column with bracket-notation, we can access it using dot-notation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f20768f",
   "metadata": {},
   "source": [
    "### Explicitly make copy when working with filtered data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612e7693",
   "metadata": {},
   "source": [
    "A typical data science workflow consists of a) filtering data to relevant cases only, and b) modifying the resulting subset. The first step often involves removing missing values, or limiting the analysis to a certain subset of interest. It is important to realize that Pandas’ filtering does not copy the interesting cases in memory, it may instead just create a view, i.e. re-use the same location in computer memory but just limit access to certain part of it. This is a very good idea in terms of conserving memory and avoiding unnecessary copy operations. However, this may cause warnings and errors when modifying the filtered data later. We demonstrate this on the same dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564ee117",
   "metadata": {},
   "source": [
    "Select only large countries (population over 20M):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ebef9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "large = countries[countries.population > 20]\n",
    "large"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4729adf",
   "metadata": {},
   "source": [
    "We got a subset of Malaysia and Indonesia. Now let’s add another variable to these large countries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dcda03",
   "metadata": {},
   "outputs": [],
   "source": [
    "large[\"language\"] = [\"Malay\", \"Indonesian\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baa4b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "large"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ffd3a0",
   "metadata": {},
   "source": [
    "Note the warning: A value is trying to be set on a copy of a slice…. This tells you that filtering countries[countries.population > 20] did not create a new data frame but a view of the existing one in memory, and Pandas is unhappy with the code modifying just a part of the original data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ff8046",
   "metadata": {},
   "source": [
    "Although the result appears correct here, do not rely on this approach! It may or may not work, depending on the exact memory layout of the dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c619c171",
   "metadata": {},
   "source": [
    "Fortunately, the solution is very simple. We need to make an explicit copy with .copy method before we start any modifications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d1c084",
   "metadata": {},
   "outputs": [],
   "source": [
    "large = countries[countries.population > 20].copy()  # explicit copy\n",
    "large[\"language\"] = [\"Malay\", \"Indonesian\"]\n",
    "large"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51388c0b",
   "metadata": {},
   "source": [
    "Now the modification works without a warning.\n",
    "\n",
    "Explicit copy is not needed before you start modifying data, you can do various filtering steps without .copy as long as you make the copy before modifications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa943705",
   "metadata": {},
   "source": [
    "#### Modifying index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163b2e2f",
   "metadata": {},
   "source": [
    "The index that is attached to series’ and data frames is potentially a useful and iformative tool. But sometimes it is not very useful. For instance, when you load data from disk, then the index defaults to be the row number, and this is rarely what we are interested in. In such cases one may want to change the index. If you want to create a new index then you can just assign it to df.index. For instance, we can just assign country names as index to our data frame of large countries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07916727",
   "metadata": {},
   "outputs": [],
   "source": [
    "large.index = [\"Malaysia\", \"Indonesia\"]\n",
    "large"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25d2dff",
   "metadata": {},
   "source": [
    "Alternatively, we can convert a column to index with .set_index() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404fa92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "large.set_index(\"capital\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaf38ab",
   "metadata": {},
   "source": [
    "This will remove the column “capital” from data frame as its values will be in index instead. Note that by default, .set_index() returns a new data frame instead of modifying it in place, so if you want to preserve it, you have to store it in a new variable. The opposite–converting the index into a column can be done with .reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e82785f",
   "metadata": {},
   "source": [
    " ### Indexing: summary and comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba9a41f",
   "metadata": {},
   "source": [
    "Indexing data is complex. Here we repeat and summarize the main methods we have discussed so far. First create three objects, a numpy matrix, a data frame, and a series. The first two are 2-dimensional but the last one 1-dimensional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44495551",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.array([[1507, 12478],\n",
    "              [-500, 11034],\n",
    "              [1537, 8443],\n",
    "              [1591, 6810]])\n",
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66bd038",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(M, columns=[\"established\", \"population\"],\n",
    "                  index=[\"Mumbai\", \"Delhi\", \"Bangalore\", \"Hyderabad\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1901a38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(M[:,0], index=df.index)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9274cdc",
   "metadata": {},
   "source": [
    "Extract rows/columns by number (integer):\n",
    "\n",
    "Numpy array: just use the numbers in brackets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069bc45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "M[1,0]  # second row, first column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4491b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "M[2,:]  # third row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321314cd",
   "metadata": {},
   "source": [
    "Data frames: use iloc and brackets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e108ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1,0]  # second row, first column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c96c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[2,:]  # third row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0e6c28",
   "metadata": {},
   "source": [
    "Series: use iloc and brackets (but these are just 1-dimensional):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f3112e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.iloc[1]  # second row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5747b379",
   "metadata": {},
   "source": [
    "Extract using index (city names/column names):\n",
    "\n",
    "numpy array: not possible\n",
    "Data frames: use loc and brackets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f307564",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"Delhi\",\"established\"]  # second row, first column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9aca21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"Bangalore\",:]  # third row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ea64f3",
   "metadata": {},
   "source": [
    "Series: use loc (but not columns here):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257f37be",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.loc[\"Delhi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e83209",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
